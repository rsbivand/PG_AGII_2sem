# Day 1

## Introducing Spatial Econometrics {#sec-why}

### Why is spatial data special? {#sec-why-special}

The three kinds of spatial data [@cressie:93] are spatial point patterns, 
geostatistical data observed at sample stations for prediction to unobserved 
locations, and areal data, also known as lattice data. In the case of spatial 
point patterns, it is assumed that all points are known, and the point 
process of interest is that driving the patterning of the points, for 
example that they are more clustered than if they were randomly distributed 
over the study area. Geostatistical modelling developed from hydrology and 
mining (environmental science) to estimate areas or volumes of quantities 
of interest, where more variability in the variables observed might suggest 
the need for sample locations to be closer to each other. While spatial 
econometrics has some links with spatial point patterns [e.g. @arbia01; 
@marconetal15; @marcon+puech17; @marcon+puech23], and geostatistics 
[e.g. @dearmon+smith21], areal or lattice spatial data are much more 
commonly analysed. 
    \index{spatial point patterns}
    \index{geostatistics}
    \index{spatial statisics}

Areal or lattice spatial data may be aggregates within administrative 
boundaries, such as municipalities, counties or census tracts, or may 
be points representing observations that do not reasonably match 
observations on a continuous surface as would have suited a geostatistical 
approach. In preparing data for modelling, support is often changed when, 
for example, night-time light intensity observed over raster cells is 
aggregated to irregular polygons, or read off by dropping points onto the 
raster cells. By support, we mean the geometry of the initial observation 
[@pebesma+bivand:23 pp. 49--54], so that when we for example use the 
centroid of an areal observation in place of its boundaries, we change 
the meaning of the variables - the population count for the polygon is 
not the same as the count at the centroid point. 
    \index{areal data}
    \index{lattice data}
    \index{support}

Change of support [@gotway+young:02] remains a largely unresolved, even 
unseen, problem, such as reading off data from sources with a different 
support than the modelled variable - like register data address points on 
other aggregate or estimated variables. Change of support implies 
acceptance that the transformed data are an estimate with a distribution, 
and that this uncertainty is often not carried through to the target 
estimation. This problem affects temporal data, but here the possible 
implied smoothing incurred when changing temporal units (hours, days, 
weeks, quarters, years) is better understood. What are the specific 
challenges involved in analysing areal spatial data?
    \index{change of support}

Temporal autocorrelation and cross-correlation are quite well understood, 
an observation of a continuous variable at time point or interval $t$ is 
likely to be more similar to the value at $t-1$ than when the time lag is 
greater, unless periodicity is more dominant. Two variables may well co-vary 
in time; knowing the degree of co-variation and autocorrelation, forecasts 
can be made readily. For time series, we know that present values depend 
in some degree on past values, observed at points or intervals of time for 
which entities of observation have an acknowledged status.
    \index{temporal autocorrelation}

Understanding of spatial autocorrelation is less simple, partly because it 
also includes the more fluid association of observed values with 
observational units. A classic case is the discussion following the 
presentation of a paper in anthropology by Tylor on marriage and 
descent laws and customs [@tylor89]. In the discussion - printed with 
the paper, Galton raises the question of the independence of the reported 
observations (Galton's Problem is also known as phylogenetic 
autocorrelation):
    \index{observational units}
    \index{spatial autocorrelation}
    \index{Galton's problem}

> It was extremely desirable for the sake of those who may wish to study 
the evidence for Dr. Tylor's conclusions, that full information should be 
given as to the degree in which the customs of the tribes and races which 
are compared together are independent. It might be, that some of the 
tribes had derived them from a common source, so that they were duplicate 
copies of the same original. Certainly, in such an investigation as this, 
each of the observations ought, in the language of statisticians, to be 
carefully "weighted." It would give a useful idea of the distribution of 
the several customs and of their relative prevalence in the world, if a 
map were so marked by shadings and colour as to present a picture of 
their geographical ranges. [@tylor89 p. 270]
    \index{Galton's problem}

The speaker responded:

> The difficulty raised by Mr. Galton that some of the concurrences might 
result from transmission from a common source, so that a single character 
might be counted several times from its mere duplicates, is a difficulty 
ever present in such investigations, as for instance in the Malay region, 
where groups of islands have enough differentiation in their marriage 
systems to justify their being classed separately, though traces of common 
origin are at the same time conspicuous. The only way of meeting this 
objection is to make separate clsssification depend on well marked 
differences, and to do this all over the world. [@tylor89 p. 272]
    \index{Galton's problem}

One view of this exchange is that nearness in space and the fluid assignment 
of boundaries between observations may affect our view of how many valid 
observations have been made. Is $n$ $n$ or some reduced number reflecting 
the common origins of the data reported? The assignment of bourdaries 
between observations, entitation, is a key concept in the modelling of 
spatial interaction [@wilson:00; @wilson:02; @wilson:12], where often 
unobservable micro-level movements are tallied by meso-level containers. 
As @openshaw+taylor79 showed, the "modifiable areal unit problem" (MAUP), can 
permit the re-arrangement of component spatial sub-units into higher-level 
contiguous units that give the desired outcome (also known as gerrymandering, 
creating voting districts to ensure desired outcomes). 

@yule+kendall:58 distinguish clearly between modifiable units of observation 
and units that cannot be modified by subdivision or aggregation (temporal 
units are also modifiable). If units are modifiable, then any results 
from analysis will be valid only in relation to the units:

> They have no absolute validity independently of those units, but are 
relative to them. They measure, as it were, not only the variation in 
the quantities under consideration, but the properties of the unit-mesh 
which we have imposed on the system in order to measure it. 
[@yule+kendall:58, p. 312]

An extension of this 
view is seen where the units of observation chosen do not address important 
sources of variation in the response; @kendall39 analysed crop productivity 
in England by crop counties for which data were readily available, but was 
criticised in discussion for not using soil or climate classifications 
in their place by Dudley Stamp, who was directing the Land Utilisation 
Survey of Britain at that time:
    \index{spatial interaction}
    \index{entitation}
    \index{modifiable areal unit problem}

> ... the author had partly anticipated his main criticism - namely, that 
the foundation of data actually available was at the present time totally 
inadequate to support the superstructure which he had erected on it. ...  
it would be difficult to find any division of England more unsuitable for 
the arrangement of the superstructure than the administrative counties. 
[@kendall39, p. 52]

The speaker responded:

> It was an inherent defect in this work, as far as it was a practical 
description of the geography of the country, that it did deal with 
particular counties and not with farming districts. Such value as might 
be claimed for the paper lay in the nature of the trial methods rather 
than in the results themselves, but he did differ from Dr. Stamp on one 
point. Dr. Stamp, if Mr. Kendall understood him correctly, suggested a 
division of the country on climatic or pedological lines. Mr. Kendall 
thought that if one had to select smaller areas within the county for 
study, one would select them on a farming type basis, not on a 
geographical basis. Apart from soil and climate the existing organization 
of the farm had a powerful influence on its nature and on its productivity. 
[@kendall39, p. 61]

An overlapping view on Galton's Problem is that, assuming that the spatial 
units of observation are accepted as given, spurious correlation due to 
position may arise from unobserved spillover between nearby observations; 
@student:14 touches briefly on agricultural trial plots in describing this 
aspect of the problem as treatments may leach between neighbouring plots. 
Student had been concerned in several contexts with the effective degrees 
of freedom of a collection of observations. Positive spillover, leading 
to more likeness between neighbours, would clearly reduce the effective 
count of independent observations. @stephan:34 gives us a powerful picture 
of the problem:
    \index{spillover}
    \index{Galton's problem}


> Data of geographic units are tied together, like bunches of grapes, not 
separate, like balls in an urn. Of course mere contiguity in time and space 
does not of itself indicate lack of independence between units in a 
relevant variable or attribute, but in dealing with social data, we know 
that by virtue of their very social character, persons, groups and their 
characteristics are interrelated and not independent. [@stephan:34, p. 165]

Tobler expresses his view, perhaps the view that is most often cited in 
discussing spatial data, in this way:
    \index{spatial autocorrelation}

> ... the first law of geography: everything is related to everything else, but near things are more related than distant things. [@tobler:70, p. 236]

However, @olsson:70 asks whether the unquestioning application of the ubiquity 
of spatial autocorrelation, as the only lens through which to view spatial 
data, is wise: 
    \index{spatial autocorrelation}

> The existence of such autocorrelations makes it tempting to agree with 
Tobler (1970, 236 [the original refers to the pagination of a conference 
paper]) that 'everything is related to everything else, but near things 
are more related than distant things.' On the other hand, the fact that 
the autocorrelations seem to hide systematic specification errors suggests 
that the elevation of this statement to the status of 'the first law of 
geography' is at best premature. At worst, the statement may represent 
the spatial variant of the post hoc fallacy, which would mean that 
coincidence has been mistaken for a causal relation. 
[@olsson:70, p. 228; cf. @pebesma+bivand:23, p. 210]
    \index{spatial autocorrelation}
    \index{mis-specification}

Specification errors of the kind concerning Olsson may be manifold, such as 
inappropriate entitation, inappropriate functional form, and omitted 
variables among others. Standard tests for spatial autocorrelation, like 
tests for temporal autocorrelation, often pick up other causes of 
mis-specification than the mutual dependence of observations that the 
tests were created to detect [@schabenberger+gotway:2005; @mcmillen:03]. 
Inappropriate entitation may involve the spatial scale of the empirical 
processes of interest, where the units of observation may be too large to 
pick up the phenomena being observed, or the footprint of the observed 
phenomenon may be split up among many units of observation (Galton's Problem). 
The interaction of scale, heterogeneity - based on scale, functional form, 
and/or missing covariates - and spatial autocorrelation has been a major 
topic of debate in numerical ecology for many years [@drayetal12].
    \index{spatial autocorrelation}
    \index{mis-specification}
    \index{entitation}
    \index{functional form}
    \index{Galton's problem}
    \index{spatial scale}
    \index{spatial heterogeneity}

At this point it might be tempting to step back, sensing that spatial
data is special, not so much specially promising, but more specially
challenging [@ripley:88]. However, if the data to hand or the data to be
collected are spatially located, it is sensible to accept the challenges
that analysis of such data may entail. The next section will depict
how spatial econometrics was created in the form in which we now know
it, to address som of the challenges and to benefit from some of the
opportunities presented.

## Spatial data {#sec-sd}

In section @sec-why-special, we showed why spatial data should be treated as "special" until it is shown that they do not require the application of specific methods to handle combinations of spatial autocorrelation, spatial scale and spatial heterogeneity. We did not there develop the concepts and tools needed for understanding and handling spatial data before analysis, or the presentation of results from spatial econometric models in spatial form. This treatment builds on @pebesma+bivand:23 chapters 1--6 and the R packages used there, but will also to some extent indicate where that software usage is matched in Python and elsewhere, for example @reyetal:23; for a comparative description, see @bivand:22. If the reader is unfamiliar with data of this kind, they may benefit from @lovelaceetal:19.

### Spatial data basics {#sec-sd-basics}

Spatial data are observations on variables, be they categorical, ordinal or continuous. The observations are associated with a position in space, where space is often represented as (sets of) coordinate tuplets on a map; spatial data are also found in bioinformatics and medical imaging, but here we are concerned with geographical spatial data. 

Geographical spatial data take two forms: spatial vectors and spatial rasters. Spatial vector objects are most often represented by geometries of sets of pairs of coordinates known as eastings and northings, or longitude and latitude, forming points, lines or polygons; three-dimensional spatial vectors are not often used but may be provided by data sources. Spatial raster objects are regular square or rectangular grids of cells, most like digital images. Spatial rasters are fixed to a spatial point of origin and the locations of cells can be found from the point of origin by stepping out from the origin cell and summing the distances crossing intervening calls measured by the size or resolution of the cells. Rasters have one or more bands, and may also be termed spatial data cubes, structured by two or three spatial dimensions (three if height/depth is included) and a time dimension in addition to bands containing sensor measurements.

While spatial raster objects include attribute data - observations on variables taken at the location of each cell, spatial vector objects do not have to do so. Observations on variables of interest are linked to geometries through a common key or identifier. The key linking the observations with the spatial vector geometries may often be a standard code published and updated by a government statistical office. Not infrequently, the data are acquired or downloaded including the key, and the geometries of the spatial objects are acquired or downloaded separately, to be merged by the observation keys afterwards. Noting the timestamp specifying the validity of geometries and keys is always sensible, as both keys and geometries change over time. We will return to the representation of time in spatial panel objects, where the geometries are invariant but variables of interest are observed over successive time periods.

For the present, spatial data will be taken as-is; we will return to reading and writing spatial data from and to files in Section @sec-sd-io. The comprehensive R archive network (CRAN) provides software packages and short summaries called task views listing packages useful for particular tasks. The Spatial task view (https://cran.r-project.org/view=Spatial) lists packages accessing or providing specific data sources of interest. Here we will use three such packages: `chilemapas` with administrative boundaries for Chile, and `rgugik` for Poland, `elevatr` for spatial raster elevation data, and `osmdata` for OpenStreetMap information. The representation of the spatial vector data is handled by the `sf` package: 

```{r chile1, size="footnotesize"}
Sys.setenv("PROJ_NETWORK"="ON")
library(sf)
```
```{r chile1a, size="footnotesize", message=FALSE}
library(chilemapas)
```
```{r chile1b, size="footnotesize"}
mapa_comunas |> data.frame() |> 
  st_as_sf(sf_column_name="geometry") -> mc_sf
mc_sf
```

The `mapa_comunas` data object stored in the `chilemapas` package is represented as a tibble and an `sf` object. Because most model fitting objects expect data as a `data.frame` not a `tbl` also known as a tibble, we coerce to `data.frame` and re-construct the `sf` object using the `sf::st_as_sf` method for `data.frame` objects. The disparity between `data.frame` and `tbl` objects is that when a single column of a `data.frame` is selected with the `[` method, it becomes a vector by default, but the `[` method on a single column of a `tbl` object returns a `tbl` by default. The `geometry` column is an `sfc` object, a list column of `sfg` objects, where `sfg` means "Simple Feature" geometry.

```{r chile2, size="footnotesize"}
st_geometry(mc_sf)
```

The geometry column contains 345 multi-polygon objects, containing the boundaries of Chilean municipalities in 2017, clipped to the coastline. They are multi-polygons because at least some municipalities are composed of island and mainland parts. The short summary printed here also states that the geometries have a geodetic coordinate reference system (CRS), here specified as SIRGAS 2000. We return to coordinate reference systems in the next section @sec-sd-crs, but note that area calculation is conducted on the specified ellipsoid using the `s2` by default, not on the plane. 

Let us find the area of Región del Maule, region `"07"`, of which Taule is the capital city, using the region key column in the `sf` object named `mc_sf`. First we subset the municipalities to the desired region, then union the municipalities in Región del Maule before finding the area of the region as a whole. 

```{r chile3, size="footnotesize"}
mc_sf |> subset(subset=codigo_region == "07") -> maule_sf
maule_sf |> st_union() |> st_area() |> units::set_units("km2")
```

The result agrees adequately with 30,296.1 square kilometres given by [Wikipedia](https://en.wikipedia.org/wiki/Regions_of_Chile), as the details of administrative boundaries and hence the computed area are compromises between detail and the size of the data object stored in the package. By default the results of length or area calculations for spherical coordinates are returned by `s2` in metres or square metres, so we convert to square kilometres.

`sf` objects pay attention to the support of variables, whether they may be classed as constant, aggregate, or identity. Constant variables are constant across the whole area of a polygon, for example a land use category. Aggregate variables may be counts, rates based on counts, or densities of counts by polygon area. Identity variables uniquely identify the geometries. In the case of the Región del Maule data set, no definitions have so far been provided, so when we change support from polygon to point by computing the spherical centroid, a warning is given [see @pebesma+bivand:23, pp. 49--52]. `st_agr` returns the current state of the factor (categorical object) for the non-geometry variables included in the `sf` object:

```{r chile4, size="footnotesize"}
st_agr(maule_sf)
maule_sf |> st_centroid() -> maule_sf_pt1
```

We can avoid the warning by taking the centroid of the geometries alone, of the `sfc` object rather than the `sf` object:

```{r chile5, size="footnotesize"}
maule_sf |> st_geometry() |> st_centroid() -> maule_sfc_pt2
```

Alternatively, since there are few non-geometry columns in the data set, we can assign the appropriate values to them, so that since the change of support does not change the meaning of the variables, no warning is given:

```{r chile6, size="footnotesize"}
maule_sf |> 
  st_set_agr(c(codigo_comuna="identity",
               codigo_provincia="identity", 
               codigo_region="constant")
            ) -> maule_sf_agr
st_agr(maule_sf_agr)
maule_sf_agr |> st_centroid() -> maule_sf_pt3
```

The three remaining packages download spatial data from public sources rather than pre-packaging them for use. `elevatr` can be used to download global elevation data as a spatial raster; until version 1 of the package is released, it returns a `"RasterLayer"` as defined in the legacy `raster` package, but from 1.0 will return a `"SpatRaster"` defined in the `terra` package. Here we specify our area of interest by passing the `sf` spatial vector object for Región del Maule, and clip the output to the boundary of the region, setting negative values to missing:

```{r chile7, size="footnotesize"}
library(elevatr)
library(terra)
maule_sf |>  get_elev_raster(z = 7,
 clip = "locations", neg_to_na = TRUE) |> 
 rast() -> maule_elev
maule_elev
```

The raster has one layer (band), with a square (geodetic) grid with a resolution of about 0.005 degrees, 18.03 arc seconds in both dimensions, 371 rows and 493 columns. 

Let us now access OpenStreetMap data using `osmdata` [@padghametal:17], first subsetting to the city of Talca, the capital of Región del Maule. To set up a query, we need to build an OpenStreetMap Overpass query using a bounding box of our area of interest. Since it can be difficult to know what kinds of data have been contributed, we add the `"names"` feature, pulling in everything in the rectangle defined in degrees of longitude and latitude - obviously the top and bottom of the rectangle are actually curves, because the rectangle is on the surface of an ellipsoid. Having created the query `talca_q`, we can extract the data for all features with names:

```{r chile8, size="footnotesize"}
maule_sf |> subset(subset = codigo_comuna=="07101") -> talca_sf
library(osmdata)
talca_sf |> st_bbox() |> opq() |>
 add_osm_feature(key = "names") -> talca_q
```

```{r chile8a, size="footnotesize", eval=FALSE}
talca_q |> osmdata_sf() -> talca_osm_sf
```
```{r chile8b, size="footnotesize", echo=FALSE, warning=FALSE}
talca_osm_sf <- try(base::readRDS("Datasets/sd/talca_osm_sf.rds"), silent=TRUE)
if (inherits(talca_osm_sf, "try-error")) talca_osm_sf <- base::readRDS("../Datasets/sd/talca_osm_sf.rds")
```
```{r chile8c, size="footnotesize"}
talca_osm_sf
```

The output object is a list of components, some of which are `sf` objects. If we take the point objects, we can attempt to subset to those said to offer take-away service, that is those for which the `takeaway` variable is not coded `NA` - missing. 

```{r chile9, size="footnotesize"}
talca_osm_sf$osm_points -> talca_pts
talca_pts |> subset(subset = !is.na(takeaway), 
 select = c(osm_id, name, amenity, cuisine,
  takeaway, geometry)) -> talca_takeaways
talca_takeaways
```

There only appear to be 11 such establishments, but perhaps these are the ones whose locations grateful clients (or ambitious proprietors) have contributed to OpenStreetMap.

The `rgugik` package [@dyba+nowosad:21] does not bundle the municipality boundaries of Poland as `chilemapas` did for Chile, but downloads them from the Polish Head Office of Geodesy and Cartography (GUGIK) online. The object returned from a query to the boundaries of the Gdańsk county administrative unit is an `sf` object with a single variable, the identification key.

```{r pl1, size="footnotesize"}
library(rgugik)
gd_sf <- borders_get(county = "Gdańsk")
gd_sf
```

Again, we can use the `sf` object to access elevation data, here returned with about 88 metre resolution, as the input object has a projected coordinate reference system:

```{r pl2, size="footnotesize"}
gd_sf |>  get_elev_raster(z = 9,
 clip = "locations", neg_to_na = TRUE) |> rast() -> gd_elev
gd_elev
```

As we just observed, `gd_sf` has a projected coordinate reference system, so needs to be transformed to a geodetic coordinate reference system before the creation of an Openpass query, here for `"amenity"` features:

```{r pl3, size="footnotesize"}
gd_sf |> st_transform(crs = "OGC:CRS84") |> st_bbox() |>
 opq() |> add_osm_feature(key = "amenity") -> gd_q
```
```{r pl3a, size="footnotesize", eval=FALSE}
gd_q |> osmdata_sf() -> gd_osm_sf
```
```{r pl3b, size="footnotesize", echo=FALSE, warning=FALSE}
gd_osm_sf <- try(base::readRDS("Datasets/sd/gd_osm_sf.rds"), silent=TRUE)
if (inherits(gd_osm_sf, "try-error")) gd_osm_sf <- base::readRDS("../Datasets/sd/gd_osm_sf.rds")
```
```{r pl3c, size="footnotesize"}
gd_osm_sf
```

Once again we extract the locations of registered take-away outlets, of which many more seem to have been contributed to OpenStreetMap than in the case of the bounding box surrounding the city of Talca:

```{r pl4, size="footnotesize"}
gd_osm_sf$osm_points -> gd_pts
gd_pts |> subset(subset = !is.na(takeaway),
 select = c(osm_id, name, amenity, cuisine,
  takeaway, geometry)) -> gd_takeaways
gd_takeaways
```


### Coordinate reference systems {#sec-sd-crs}

Since 2019, the representation of coordinate reference systems (CRS) have stabilised in the well-known text format known as WKT2-2019, which is an international standard. The representation supports both two and three dimensional structures, and as implemented in open geospatial software (PROJ) uses definitions stored in a regularly updated database bundled with the software. The database also contains tables defining transformations between CRS, now often based on open access transformation grid files downloaded on-the-fly if required. In parts of the world subject to rapid tectonic movement (the old city centre of Talca, Chile was badly damaged by an earthquake in 2010), CRS change frequently if more by centimetres than by metres. 

```{r chile-crs1, size="footnotesize"}
st_crs(talca_sf)
```

The definition used for stored objects in the `chilemapas` package is the geographical CRS in decimal degrees called `"SIRGAS 2000"` based on the `"GRS 1980"` ellipsoid - geodetic reference system of 1980. The provided data have as is often the case swapped axes compared to the CRS definition. Most geographical information systems keep to $x$, $y$, that is easting, northing or longitude, latitude axis order. Before version 1.0, `elevatr` reverts to the legacy PROJ4 string representation seen in the summaries above.

`osmdata` and OpenStreetMap appear to assume that all modern geographical coordinate reference systems use `"EPSG:4326"` as is said to apply to consumer global positioning systems (GPS) devices. This is somewhat accurate, but there is no fixed definition. The definition is usually updated locally for each major tectonic plate, so the WKT2-2019 representation of the CRS used here is as a datum ensemble, with at best two metre accuracy, often worse, as we are noe fourty years on from where the tectonic plates were when `"WGS 84` was agreed in 1984. Some surveyors have argued that all coordinate tuples should be timestamped, in order to permit the tracking of the movement of points across the earth's surface and their vertical change as well. 

```{r chile-crs2, size="footnotesize"}
st_crs(talca_takeaways)
```

So while the `"SIRGAS 2000"` object and the `"WGS 84` refer approximately to the same representation, some `sf` predicates and operations on geometries may see them as differing, as for example checking that the Talca take-aways found in the bounding box do lie within the municipality boundaries:

```{r chile-crs3, size="footnotesize"}
try(st_within(talca_takeaways, talca_sf))
```

Since we know that both are based on the`"GRS 1980"` ellipsoid, we can overwrite the CRS of the OpenStreetMap take-away outlets location output to bring it into agreement with `"SIRGAS 2000"`, resulting in finding that all the outlets all lie within the municipality boundaries:

```{r chile-crs4, size="footnotesize"}
talca_sf |> st_crs() -> sirgas2000
talca_takeaways |> st_set_crs(sirgas2000) |>
 st_within(talca_sf) |> unlist() |> as.logical()
```

@alvescostaetal:23 document current status for the development of SIRGAS, and helpfully show how an increase in ground GPS/GNSS (Global Navigation Satellite Systems from all providers) station density helps track terrestrial movement, which in parts of Chile exceeds 20mm per year. While the movement of the earth's crust is one source of inaccuracy, another is measurement error, and yet another computational error from repeated use of trigonometrical functions and approximated transformation coefficients. A lack of clarity in defining CRS can lead to the wrong assignation of for example points to polygons. 

The Universal Transverse Mercator projection (zone 19 south) is often used for central Chile, and this specific version uses the same `"SIRGAS 2000"` datum as the input data objects from `chilemapas`:

```{r chile-crs5, size="footnotesize"}
st_crs("EPSG:31979")
```

If we check to see which candidate coordinate operations are available, we see that in fact projection accuracy is as good as possible, because the datum definitions of the two CRS are the same:

```{r chile-crs6, size="footnotesize"}
sf_proj_network(TRUE)
sf_proj_pipelines("EPSG:4674", "EPSG:31979")
```

If we replace the target CRS with `"SIRGAS-Chile 2021 UTM 19S"`, `sf_proj_pipelines` still only finds one candidate, but because no datum transformation from `"SIRGAS 2000"` to `"SIRGAS-Chile 2021"` is found in the database, we must accept unknown ballpark accuracy:

```{r chile-crs6a, size="footnotesize"}
sf_proj_pipelines("EPSG:4674", "EPSG:20049")
```

Many national and international mapping agencies have provided open access transformation grids that PROJ can use on-the-fly (https://cdn.proj.org/), but neither Chile not SIRGAS have contributed any such grid so far. Grids are more accurate than three or seven parameter transformations because they allow local crustal deformations to be applied, rather than averaged over the whole area of application. Accuracy is now much more important as GPS/GNSS has become established in navigation, precision farming, construction, etc.

Let us repeat the measurement of the area of Región del Maule after projection to `"UTM 19S"`

```{r chile-crs7, size="footnotesize"}
maule_sf |> st_union() |> st_transform(crs = "EPSG:31979") |>
 st_area() |> units::set_units("km2")
```

The area is now more than 16 square kilometres greater than the area from Wikipedia, and the area calculated by `s2` on the surface of the earth. All projections distort the rounded surface of the earth by squeezing the centre of the area of interest and stretching the edges to force it into planar form, so depending on the statutory regulations, all measured areas are approximate in one way or another.

Let us now move to the CRS of the boundary of the county of Gdańsk:

```{r pl-crs1, size="footnotesize"}
st_crs(gd_sf)
```

Poland currently uses the European Terrestrial Reference Frame (ETRF) and lies on a tectonic plate with little deformation activity, although the plate itself is moving up to 20mm a year. The projection `"ETRF2000-PL / CS92"` was adopted following the dissolution of the Warsaw Pact - mapping everywhere is driven at base by the needs of military operations.

The CRS of the take-away outlets is as for Talca:

```{r pl-crs2, size="footnotesize"}
st_crs(gd_takeaways)
```

and the transformation pipeline from `"ETRF2000-PL / CS92"` to `"WGS 84"` has an accuracy of 1 metre:

```{r pl-crs3, size="footnotesize"}
sf_proj_pipelines("EPSG:2180", "EPSG:4326")
```

Since none of these projections/transformations have required datum transformation, let us use the example of `"OSGB36 / British National Grid"` to `"WGS 84"`. We can see that the `"Ordnance Survey of Great Britain 1936"` datum uses a different ellipsoid: `"Airy 1830"` from `"GRS 1980"`:

```{r crs-osgb1, size="footnotesize"}
st_crs("EPSG:27700")
```

If we then query the database to find the most accurate transformation with enabled access to transformation grids, we can achieve 1 metre:

```{r crs-osgb2, size="footnotesize"}
sf_proj_pipelines("EPSG:27700", "EPSG:4326")
```

The parts of the grid file `uk_os_OSTN15_NTv2_OSGBtoETRS.tif` needed for the data in question can be downloaded automatically on-the-fly if PROJ network access is enabled, and cached locally for any software using PROJ for handling CRS; the grid file offsets are shown in Figure 2.4, page 25 of @pebesma+bivand:23.


## Working with spatial data

```{r pl_io0, echo=FALSE, results="hide"}
io_dir <- "Input_output"
if (!dir.exists(io_dir)) io_dir <- paste0("../", io_dir)
```


### Merging spatial data {#sec-sd-merge}

As was mentioned above in section @sec-sd-basics, spatial vector geometries are most often furnished with identification keys, permitting other data using the same key or index identifiers to be added correctly. In Poland, they have been known as `"TERYT"`, and are fairly stable over time, though border changes can occur, with new key values appearing and old values ceasing to be used, leading to breaks of series. The `rgugik` package contains a data object listing these keys together with unit names, but matching on names can be troublesome. First we will subset this object to the Pomeranian voivodeship:

```{r pl_m0, size="footnotesize"}
library(rgugik)
library(sf)
substring(commune_names$TERYT, 1, 2) -> vpom
commune_names |> subset(subset = vpom == "22") -> pom0
```

then retrieve the boundaries of municipalities in Pomerania using `"TERYT"` rather than using the names of municipalities, which are duplicated in other voivodeships:

```{r pl_m1, size="footnotesize", eval=FALSE}
borders_get(TERYT = pom0$TERYT) -> pom
```
```{r pl_m1a, size="footnotesize", echo=FALSE, warning=FALSE}
pom <- try(base::readRDS("Datasets/sd/pom_sf.rds"), silent=TRUE)
if (inherits(pom, "try-error")) pom <- base::readRDS("../Datasets/sd/pom_sf.rds")
```

Merging the `pom` object containing the `"TERYT"` keys and municipality names, with `pom_sf`, including the `"TERYT"` keys and municipality boundaries is easy, as the keys are both character objects - this matters because some keys may start with `0`, zero, and be wrongly read as integers, dropping leading zeros. The key for this voivodeship is `"22"`, so this problem is not encountered here, but often occurs. Should an identifying key with leading zeros be read as integer, it can be restored using `base::formatC` after checking the required string width:

```{r pl_m1b, size="footnotesize"}
ID <- as.integer("0012345") 
str(ID)
formatC(ID, format="d", width=7, flag="0")
```

Note that the `"TERYT"` key values returned in the `pom_sf` object include an underscore between the six digit territorial code and the trailing digit expressing the type of municipality. 

```{r pl_m2, size="footnotesize"}
dim(pom)
pom |> sapply(class) |> str()
str(pom$TERYT)
str(pom0)
```

The underscore needs to be removed before finally checking that they match:

```{r pl_m2a, size="footnotesize"}
pom$TERYT <- sub("_", "", pom$TERYT)
any(is.na(match(pom$TERYT, pom0$TERYT)))
```

Finally, the merging operation may be carried out:

```{r pl_m3, size="footnotesize"}
pom |> merge(pom0, by = "TERYT") -> pom1 
pom1
```

Having methodically made a first merge, we can move forward with three files at the municipality level from Statistics Poland's [local data bank](https://bdl.stat.gov.pl/bdl/start). These were exported as comma (or semicolon) separated value (CSV) files on February 15, 2024 - dates matter, as online data banks update their contents as inaccuracies are detected. Currently, no package provides direct access to this data bank, and for moderate data volumes, registration is required. The first file is semicolon separated, and contains population data by age group and sex (category K3, group G7, subgroup P2577) for the end of the second half-year 2022:

```{r pl_m4, size="footnotesize", eval=FALSE}
pop22 <- read.csv("Datasets/sd/LUDN_2577_2022.csv", sep=";")
```
```{r pl_m4a, size="footnotesize", echo=FALSE, warning=FALSE}
pop22 <- try(read.csv2("Datasets/sd/LUDN_2577_2022.csv", sep=";"), silent=TRUE)
if (inherits(pop22, "try-error")) pop22 <- read.csv2("../Datasets/sd/LUDN_2577_2022.csv", sep=";")
```

As with most such data, the column names need adjustment. On reading, reserved characters in R are replaced by dots, and for further work, shorter column names are helpful. Current R versions support multibyte characters across all platforms, but some files with single-byte characters can be encountered, in which case judicious use of `base::iconv` may be needed. 

```{r pl_m5, size="footnotesize"}
sapply(pop22, class)
pop22$Kod <- as.character(pop22$Kod)
names(pop22)[3:8] <- c("m_u15", "f_u15",
 "m_15_64", "f_15_59", "m_o65", "k_o60")
pop22$type <- factor(substring(pop22$Kod, 7, 7),
 levels = c("1", "2", "3"),
 labels = c("urban", "rural", "urban_rural"))
names(pop22)
```

The key column was read as integer, so needs correcting; otherwise the remaining columns seem to be formatted acceptably. A new column is created as a factor showing the type of municipality, as a factor  In addition, we The `"X"` column contains no data, and is dropped from the merging operation. We could overwrite the cumulating object on merge; here we choose to create a new object at each merge. The key is called `"TERYT"` in `pom_sf` and `"Kod"` in `pop92`, specified with `by.x` and `by.y` arguments:

```{r pl_m6, size="footnotesize"}
pom1 |> merge(pop22[, -9], by.x = "TERYT",
 by.y = "Kod") -> pom2
pom2
```

Having added the population group counts by sex for the Pomeranian municipalities, we create a new column `"pop"` summing the total population at year end 2022. We then calculate municipality areas, and divide population by area (in square kilometres) to get the population density:

```{r pl_m7, size="footnotesize"}
pom2 |> st_drop_geometry() |> subset(select = 4:9) |>
 apply(1, function(x) sum(x)) -> pom2$pop
pom2 |> st_area() |>
 units::set_units("km2") -> pom2$area_km2
pom2 |> st_drop_geometry() |>
 subset(select = c(pop, area_km2)) |>
 apply(1, function(x) x[1]/x[2]) -> pom2$density
 pom2
```

The next file contains counts of farms from the Agricultural census reporting farm income from the farm (category K34, group G637, subgroup P4139). While this file was exported from the local data bank in the same way as the previous one, it is comma-separated:

```{r pl_m8a, size="footnotesize", eval=FALSE}
ag20 <- read.csv("Datasets/sd/POWS_4139_2020.csv", sep=",")
```
```{r pl_m8b, size="footnotesize", echo=FALSE, warning=FALSE}
ag20 <- try(read.csv("Datasets/sd/POWS_4139_2020.csv", sep=","), silent=TRUE)
if (inherits(ag20, "try-error")) ag20 <- read.csv("../Datasets/sd/POWS_4139_2020.csv", sep=",")
```

Again, column names require simplification, but here there is no spurious `"X"` column - we just drop the municipality name from the merge:

```{r pl_m9, size="footnotesize"}
ag20$Kod <- as.character(ag20$Kod)
names(ag20)[3:7] <- c("farm", "non_farm_business",
 "non_farm_wages", "pension", "other_non_wage")
pom2 |> merge(ag20[,-2], by.x = "TERYT",
 by.y = "Kod") -> pom3
```


Finally, and because the agricultural census data are counts of farms, we need counts of inhabited dwellings from the population census 2021 (category K31, group G645, subgroup P4383), especially for urban municipalities; the merging process follows the lines of those above:

```{r pl_m10a, size="footnotesize", eval=FALSE}
cen21 <- read.csv("Datasets/sd/NARO_4383_2021.csv", sep=";")
```
```{r pl_m10b, size="footnotesize", echo=FALSE, warning=FALSE}
cen21 <- try(read.csv2("Datasets/sd/NARO_4383_2021.csv", sep=";"), silent=TRUE)
if (inherits(cen21, "try-error")) cen21 <- read.csv2("../Datasets/sd/NARO_4383_2021.csv", sep=";")
```
```{r pl_m10c, size="footnotesize"}
cen21$Kod <- as.character(cen21$Kod)
names(cen21)[3] <- "dwellings"
pom3 |> merge(cen21[, -c(2, 4)], by.x = "TERYT",
 by.y = "Kod") -> pom4
names(pom4)
```

In conclusion, for completeness, let us assign aggregation levels to the newly merged values:

```{r pl_m11, size="footnotesize"}
agrs <- factor(c(rep("identity", 3), rep("aggregate", 6),
 "identity", rep("aggregate", 9)),
 levels=c("constant", "aggregate", "identity"))
names(agrs) <- names(st_drop_geometry(pom4))
pom4 |> st_set_agr(agrs) -> pom5
```


### Visualising spatial data {#sec-sd-vis}

For many purposes, maps themselves are spatial data. Observations are located in space as points,  lines or polygons, and their placing yields useful contextual information when plotted. Using the `plot` methods on `terra` and `sf`, we can display the elevation raster as a background, and show the municipality boundaries with their ID keys:

```{r chile_vis1a, size="footnotesize"}
#| label: base_cl
#| fig-cap: Elevation of Región del Maule, municipalities (base graphics plot methods)
library(elevatr)
library(terra)
maule_sf |>  get_elev_raster(z = 7,
 clip = "locations", neg_to_na = TRUE) |> 
 rast() -> maule_elev
plot(maule_elev, col=rev(hcl.colors(50, "Dark Mint")))
plot(st_geometry(maule_sf), add=TRUE)
text(st_coordinates(st_centroid(st_geometry(maule_sf))),
 label=maule_sf$codigo_comuna)
```

`mapsf` provides fairly flexible map creation functionality for overlaying layers of map information on a graphics output device, following the same order as above, but permitting the improvement of label positioning. Above, we set the palette to be used for elevation to `"Dark Mint"`, which is the default for `mapsf::mf_raster`:

```{r chile_vis1b, size="footnotesize"}
#| label: mapsf_cl
#| fig-cap: Elevation of Región del Maule, municipalities (base graphics mapsf functions)
library(mapsf)
mf_raster(maule_elev, leg_pos="bottomleft",
 leg_title="elevation (m)", leg_horiz=TRUE,
 leg_size=0.8, leg_val_rnd=0)
mf_map(st_geometry(maule_sf), add=TRUE, lwd=2,
 border="grey60", col="transparent")
mf_label(maule_sf, var="codigo_comuna", overlap=FALSE,
 halo=2)
```

`tmap` is about to be upgraded, and is very concise in expressing map construction by adding successive layers to the output graphic with the `+` operator:

```{r chile_vis2a, size="footnotesize"}
#| label: tmap3_cl
#| fig-cap: Elevation of Región del Maule, municipalities (trellis graphics tmap functions)
library(tmap)
tm_shape(maule_elev) + tm_raster(n=15,
 palette=rev(hcl.colors(7, "Dark Mint"))) +
 tm_shape(maule_sf) + tm_borders() +
 tm_text("codigo_comuna")
```

Using the simplest approach, we can plot the positions of the take-away outlets registered for Talca city in OpenStreetMap, and see that they are very clustered within the boundary of the municipality:

```{r chile_vis2, size="footnotesize"}
#| label: takeaways_talca1
#| fig-cap: Location of take-away outlets in Talca
plot(st_geometry(talca_sf))
plot(st_geometry(talca_takeaways), pch=4, col=3,
 cex=2, lwd=2, add=TRUE)
```

Since it would be very useful to obtain more locational context, we can use `mapview` to view the take-away outlets on a web map background, so that we can interact with the point locations. The `mapview` methods convert the object to be displayed to `"OGC:WGS84"` if necessary, then to Web Mercator for display:

```{r chile_vis3a, size="footnotesize", eval=!knitr::is_latex_output()}
#| label: takeaways_talca2
#| fig-cap: Interactive map of take-away outlets in Talca
library(mapview)
mapview(talca_takeaways)
```
```{r chile_vis3b, echo=FALSE, results="as.is", eval=knitr::is_latex_output()}
#| label: takeaways_talca2a
#| fig-cap: Screen dump of interactive map of take-away outlets in Talca
img <- try(knitr::include_graphics("Images/sd/talca_takeaways.png"), silent=TRUE)
if (inherits(img, "try-error")) knitr::include_graphics("../Images/sd/talca_takeaways.png")
```

Moving to the data set for municipalities in the Polish voivodeship of Pomerania, we can attempt to show the density variable on an interactive map:

```{r pl_vis0a, size="footnotesize", eval=!knitr::is_latex_output()}
#| label: gd_dens0a
#| fig-cap: Interactive map of Pomeramia municipalities from rgugik, population density per square kilometre
library(mapview)
mapview(pom5, zcol="density")
```
```{r pl_vis0b, echo=FALSE, results="as.is", eval=knitr::is_latex_output(), warning=FALSE}
#| label: gd_dens0b
#| fig-cap: Screen dump of interactive map of Pomeramia municipalities from rgugik, population density per square kilometre
img <- try(knitr::include_graphics("Images/sd/gd_dens0.png"), silent=TRUE)
if (inherits(img, "try-error")) knitr::include_graphics("../Images/sd/gd_dens0.png")
```

As may be seen in the interactive map, the municipality boundaries do match the Baltic sea coastline quite well, but the jurisdiction of the municipalities extends to some coastal waters in the Gulf of Gdańsk and Zalew Wiślany; we did after all download administrative municipality boundaries using `rgugik`. We need to find another source of boundaries that agree with the coastline, and then need to take the intersection of the two sets od polygons, leaving only areas present in both. `giscoR` provides access to boundaries for European NUTS regions, in geographical coordinates by default. We then need to transform to the Transverse Mercator projection used for the download from `rgugik` before carrying out the intersection:


```{r pl_vis0c, size="footnotesize"}
library(giscoR)
pom_gisco <- gisco_get_nuts(year="2021", resolution="01",
 spatialtype="RG", nuts_id="PL63")
pom_gisco_tm <- st_transform(pom_gisco, "EPSG:2180")
pom6 <- st_intersection(pom5, pom_gisco_tm)
```

On occasion, topological operations on two objects like `st_intersection` fail because the two geometries have different coordinate reference systems, in which case, `st_transform` should be used first to bring them into agreement. If in any topological operation or predicate (such as a query like `st_intersects`), it is found that a geometry is invalid, for example the self-intersection of a polygon boundary, use `st_make_valid` on the invalid object. It can be the case that the geometry cannot be repaired, as some data providers do not check the provided geometries for validity. Since an intersection operation can yield points and lines as well as polygons, we can check the input and output geometries and re-establish their original geometry types; in this case only polygons and multipolygons were output:

```{r pl_vis0c1, size="footnotesize"}
pom5 |> st_geometry_type() |> table() -> tab5; tab5[tab5>0]
pom6 |> st_geometry_type() |> table() -> tab6; tab6[tab6>0]
pom6 |> st_cast("MULTIPOLYGON") -> pom6
```


Since the areas of some municipalities have now changed, we need to re-caluclate both areas and densities:

```{r pl_vis0d, size="footnotesize"}
pom6 |> st_area() |>
 units::set_units("km2") -> pom6$area_km2
pom6 |> st_drop_geometry() |>
 subset(select = c(pop, area_km2)) |>
 apply(1, function(x) x[1]/x[2]) -> pom6$density
```

As can be seen from Figure @gd_dens1a, the graphical representation is now more legible; coastlines and boundaries are typically read as contextual location information.

```{r pl_vis0e, size="footnotesize", eval=!knitr::is_latex_output()}
#| label: gd_dens1a
#| fig-cap: Interactive map of Pomeramia municipalities from rgugik, corrected population density per square kilometre
mapview(pom6, zcol="density")
```
```{r pl_vis0f, echo=FALSE, results="as.is", eval=knitr::is_latex_output(), warning=FALSE}
#| label: gd_dens1b
#| fig-cap: Screen dump of interactive map of Pomeramia municipalities from rgugik, corrected population density per square kilometre
img <- try(knitr::include_graphics("Images/sd/gd_dens1.png"), silent=TRUE)
if (inherits(img, "try-error")) knitr::include_graphics("../Images/sd/gd_dens1.png")
```

Two minor points before we move on, first that the distribution of the variable which we want to map does matter. The population density of Pomeranian municipalities is far from being symmetric, as this density plot shows:

```{r pl_vis1a, size="footnotesize"}
#| label: pl_vis1a
#| fig-cap: Density plot of population density, Census 2021, Pomeranian municipalities
plot(density(pom6$density))
```

In this case, in thematic cartography we should create class intervals for display using quantiles or other suitable methods. `mapsf` provides a geometric progression `"geom"` method for creating class intervals for skewed variables:

```{r pl_vis1b, size="footnotesize"}
#| label: pl_vis1b
#| fig-cap: Population density, Census 2021, Pomeranian municipalities
mf_map(pom6, var="density", type="choro", breaks="geom",
 nbreaks=7)
```

The choice of breaks style does matter for communicating the important traits of the variable in question in thematic cartography, here as a choropleth map.

The second display problem is associated with showing the kind of classes implied by the data. For a categorical variable and few classes, the classes are taken from the categories, and unlike the examples above using sequential palettes, this uses a qualitative palette:

```{r pl_vis1c, size="footnotesize"}
#| label: pl_vis1c
#| fig-cap: Municipality type, Pomeranian municipalities
mf_map(pom6, var="type", type="typo")
```

When the variable is crosses a specified mid-point, like regression residuals, a sequential palette is not appropriate, and a diverging palette should be chosen. `tmap::tm_fill` attempts to make reasonable choices in this situation; here the deviance of the proportion of the municipality population less than 16 years old from its mean:

```{r pl_vis2a, size="footnotesize"}
pom6$young <- 100*(pom6$m_u15 + pom6$f_u15)/pom6$pop
pom6$young_res <- residuals(lm(young ~ 1, data=pom6))
```

```{r pl_vis2b, size="footnotesize"}
#| label: pl_vis2b
#| fig-cap: Proportion of population under 16 years of age, residuals from the mean, Pomeranian municipalities, 2022
tm_shape(pom6) + tm_fill("young_res", style="quantile",
 n=11, midpoint=0, palette="RdBu") + tm_borders()
```



### Reading and writing spatial data {#sec-sd-io}


For the present, we will only consider the reading and writing of spatial vector data using functions from `sf`: `st_read` and `st_write`. Further, while it is still regretably the case that many organisations still use the  `"ESRI Shapefile"` (actually most often a bundle of at least four files) for sharing data, the GeoPackage format, `"GPKG"`, should be preferred because it represents CRS properly, does not restrict field (variable) names to 10 characters, does use multibyte characters, and does store numerical fields in binary rather than text format. For commonly used formats, the format-specifiic driver is chosen from the file extension:

```{r pl_io1, size="footnotesize", warning=FALSE}
fn <- paste0(io_dir, "/pom6.gpkg")
if (file.exists(fn)) tull <- file.remove(fn)
try(st_write(pom6, fn))
```

```{r pl_io1a, size="footnotesize", warning=FALSE, echo=FALSE}
lf <- list.files(io_dir, pattern="pom6.gpkg")
if (length(lf) > 0L) tull <-file.remove(paste(io_dir, lf, sep="/"))
```

Unfortunately, our intersection of the GISCO voivodeship outline added a number of variables to the data set, including one called `"FID"` , which is a reserved word for many spatial data formats, meaning "Feature IDentifier", and must be an integer. Now it is a character vector, so we replace it by a compliant integer vector with unique values; we could also have dropped it:

```{r pl_io2, size="footnotesize", warning=FALSE}
str(pom6$FID)
pom6$FID <- 1:nrow(pom6)
st_write(pom6, dsn=fn)
```

To read, `st_read` will try to identify the format and use the appropriate driver automatically; if the data source containd multiple layers, the first will be read by default:

```{r pl_io3a, size="footnotesize"}
pom6a <- st_read(dsn=fn)
```

When we do a simple check to see if output and input are identical - and find that they are not:

```{r pl_io3b, size="footnotesize"}
isTRUE(all.equal(st_geometry(pom6), st_geometry(pom6a)))
```

When written to the external format, the order of the columns changes, as the geometry column is moved to the end on reading. This re-orders the columns, which contain the same information as before but the order differs:

```{r pl_io3c, size="footnotesize"}
names(pom6)
names(pom6a)
```

In addition, the `"area_km2"` column loses its units definition, and the `"type"` column becomes a character vector, not a factor. Such differences are trivial and to be expected, but imply that if an object is to shared with collaborators, any shared script should use the object as read from file, especially if column order rather than column names are used in analysis. After reading, we can restore the representation of the columns before starting work:

```{r pl_io3d, size="footnotesize"}
pom6a$type <- factor(pom6a$type)
pom6a$area_km2 <- units::set_units(pom6a$area_km2, "km2")
```


## Creating spatial weights objects {#sec-sd-w}



Chapter 14 of @pebesma+bivand:23 provides a fairly up-to-date account of how one may construct `"nb"` neighbour objects, and from these `"listw"` weights objects. In the following chapters, these objects will be used extensively in modelling, and will often be referred to as spatial weights matrices. While their description in terms of linear algebra as matrices is reasonable, their representation as dense $n$ by $n$ matrices is much less reasonable, as in most cases, only a very few elements of such a matrix are non-zero. This means that sparse representations are certainly preferable in terms of storage and efficiency, and repeated multiplication by zero is simply wasteful. `"nb"` neighbour objects, and `"listw"` weights objects are sparse representations, where the `"nb"` object records which objects $j$ are neighbours of $i$ for each $i$, and `"listw"` objects add in the weights assigned to each such 
$i$-$j$ relationship. 

We will use the `spdep` package to construct neighbour objects for the 123 Pomeranian municipalities. Since we have the boundaries of the municipalities, we can see which municipalities share boundary segments, known as rook contiguity; we add identifiers to the output object, now only to show it can be done, but later for use in out-of-sample prediction among other uses:

```{r pom_sw1, size="footnotesize"}
library(sf)
library(spdep)
(pom6a |> poly2nb(queen=FALSE,
 row.names=pom6a$TERYT) -> pom_rook_nb)
```

If we slacken our definition of contiguity to simply sharing one boundary point, to queen contiguity, we see that the problems detected here of two no-neighbour municipalities and seven disjoint subgraphs remain:

```{r pom_sw2, size="footnotesize"}
(pom6a |> poly2nb(queen=TRUE,
 row.names=pom6a$TERYT) -> pom_queen_nb)
```

One possible reason for such problems is that boundaries provided by public agencies are accurate enough for their purposes, but where shared boundary points are not exactly identical. If we pass a very small distance, here one-hundredth of a millimetre, as a snap distance, the problems are resolved:

```{r pom_sw3, size="footnotesize"}
(pom6a |> poly2nb(queen=FALSE, row.names=pom6a$TERYT,
 snap=0.00001) -> pom_rook_nb)
(pom6a |> poly2nb(queen=TRUE, row.names=pom6a$TERYT,
 snap=0.00001) -> pom_queen_nb)
```

We can also see that in this case the rook and queen definitions lead to the same neighbour object; differences are more often seen in US tracts or counties with grid-like boundaries where four entities meet at a single point.

By definition, contiguity neighbours, like distance threshold neighbours are symmetric, that is if $i$ is a neighbour of $j$, $j$ must be a neighbour of $i$. This is only rarely the case when defining neighbours as the $k$-nearest points. Asymmetric neigbours lead to directed graphs, which can also be handled, but which need subsequent numerical special treatment. There may be substantive reasons for choosing asymmetric neighbours, but it is probably a good idea to spell out the reasons clearly.

It is important to establish whether no-neighbour entities really have no neighbours because in matrix terms they lead to columns and rows with only zero values. Some methods become poorly defined if observations "drop out" of analysis in this way. For similar reasons, the detection of disjoint subgraphs, that is parts of the neighbour object that are unconnected from other parts of the object, jeopardises the outcome of modelling, as spatial processes cannot travel across the whole graph. The graph we have found now can be plotted, using `st_point_on_surface` internally to provide points to represent the polygons:

```{r pom_sw4, size="footnotesize"}
#| label: pom_sw4
#| fig-cap: Queen neighbour object, Pomeranian municipalities, 2022
geom <- st_geometry(pom6a) 
plot(geom, border="grey")
plot(pom_queen_nb, geom, add=TRUE)
```

When choosing the five nearest neighbours as the neighbour criterion, with distance measured to suit the coordinate reference system of the point geometries, the outcome is most often asymmetric:

```{r pom_sw5, size="footnotesize"}
(geom |> st_point_on_surface() |> knearneigh(k=5) |>
 knn2nb(row.names=pom6a$TERYT) -> pom_k5_nb)
```
```{r pom_sw6, size="footnotesize"}
#| label: pom_sw6
#| fig-cap: Five nearest neighbour object, Pomeranian municipalities, 2022
plot(geom, border="grey")
plot(pom_k5_nb, geom, add=TRUE)
```

As Figure @pom_sw6a shows, open coastal water is crossed by links between neighbours defined in this way. For the point support Gdańsk take-away outlets and five nearest neighbours, asymmetry is expected, but as with many distance measures, this case does raise the question of whether to measure distance in a distance metric or perhaps a time metric, because crossing a busy street takes more time than walking or cycling along a street:

```{r gd_sw1, size="footnotesize"}
(gd_takeaways|> knearneigh(k=5) |>
 knn2nb(row.names=gd_takeaways$osm_id) -> gd_k5_nb)
```
```{r gd_sw1a, size="footnotesize"}
gd_k5_nb |> nb2lines(coords=st_geometry(gd_takeaways)
 ) -> gd_k5_nb_sf
```

As Figure @gd_sw2a shows, the outlets are tightly clustered into disjoint subgraphs, but on more careful consideration, the outlets are multi-function, also serving drop-in customers. An outlet only offering take-away service might be located best near peak demand conditioned by the cost of property rental and transport accessibility, but most seem to sell to multiple markets: take-away, eat in restaurant, and delivery to customer. Maybe some compete on price, but cuisine may be a differentiator as well. 

```{r gd_sw2a, size="footnotesize", eval=!knitr::is_latex_output()}
#| label: gd_sw2a
#| fig-cap: Five nearest neighbour object, Gdańsk take-away outlets, OpenStreetMap
library(mapview)
mapview(gd_takeaways) + mapview(gd_k5_nb_sf, color="red4")
```
```{r gd_sw2b, echo=FALSE, results="as.is", eval=knitr::is_latex_output(), warning=FALSE}
#| label: gd_sw2b
#| fig-cap: Screen dump of interactive map of five nearest neighbour object, Gdańsk take-away outlets, OpenStreetMap
img <- try(knitr::include_graphics("Images/sd/gd_tkwy.png"), silent=TRUE)
if (inherits(img, "try-error")) knitr::include_graphics("../Images/sd/gd_tkwy.png")
```

Having shown some methods for constructing neighbour objects, we can briefly mention the assignment of weights to the neighbour links:

```{r pom_sw7, size="footnotesize"}
pom_queen_nb |> nb2listw(style="W") -> pom_queen_lw
summary(pom_queen_lw)
```

The output of the `summary` method shows the same details as for the `nb` object, adding a tabulation by neighbour count, the weights style `"W"`, meaning that the weights are standardised so that the sum of weights for each observation is unity:

```{r pom_sw8, size="footnotesize"}
pom_queen_lw$weights |> sapply(sum) |> unique()
```

In some modelling settings, the `"B"` binary zero-one style is preferred, and there are a number of alternative ways of specifying weights. Finally, if the neighbour object contains no-neighbour entities, the `zero.policy` argument to `nb2listw` may be used to indicate that zero weights are acceptable - the obvious alternatives are to exclude such entities, or to add neighbour links so that all entities have neigbours.


